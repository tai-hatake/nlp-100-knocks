{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第4章: 形態素解析\n",
    "夏目漱石の小説『吾輩は猫である』の文章（[neko.txt](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/neko.txt)）をMeCabを使って形態素解析し，その結果をneko.txt.mecabというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ．\n",
    "\n",
    "なお，問題37, 38, 39はmatplotlibもしくはGnuplotを用いるとよい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30. 形態素解析結果の読み込み\n",
    "形態素解析結果（neko.txt.mecab）を読み込むプログラムを実装せよ．ただし，各形態素は表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をキーとするマッピング型に格納し，1文を形態素（マッピング型）のリストとして表現せよ．第4章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analyzed_file(input_file_name: str, output_file_name: str) -> None:\n",
    "    m = MeCab.Tagger('-Ochasen')\n",
    "    with open(input_file_name, encoding='utf-8') as input_file:\n",
    "        with open(output_file_name, mode='w', encoding='utf-8') as output_file:\n",
    "            output_file.write(m.parse(input_file.read()))\n",
    "\n",
    "make_analyzed_file('input/neko.txt', 'output/neko.txt.mecab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'surface': '一', 'base': 'イチ', 'pos': '一', 'pos1': '名詞-数'}, {'surface': 'EOS', 'base': '', 'pos': '', 'pos1': ''}, {'surface': '\\u3000', 'base': '\\u3000', 'pos': '\\u3000', 'pos1': '記号-空白'}, {'surface': '名前', 'base': 'ナマエ', 'pos': '名前', 'pos1': '名詞-一般'}, {'surface': 'EOS', 'base': '', 'pos': '', 'pos1': ''}, {'surface': '\\u3000', 'base': '\\u3000', 'pos': '\\u3000', 'pos1': '記号-空白'}, {'surface': '何', 'base': 'ナニ', 'pos': '何', 'pos1': '名詞-代名詞-一般'}, {'surface': '吾輩', 'base': 'ワガハイ', 'pos': '吾輩', 'pos1': '名詞-代名詞-一般'}, {'surface': 'しかも', 'base': 'シカモ', 'pos': 'しかも', 'pos1': '接続詞'}, {'surface': 'この', 'base': 'コノ', 'pos': 'この', 'pos1': '連体詞'}]\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger('-Ochasen')\n",
    "def mapping_morpheme(lines :str) -> dict:\n",
    "    array_morpheme = m.parse(lines[0]).split('\\n')\n",
    "    for line_morpheme in array_morpheme:\n",
    "        word_morpheme = line_morpheme.split('\\t')\n",
    "        if len(word_morpheme) > 1:\n",
    "            return {'surface': word_morpheme[0], 'base': word_morpheme[1], 'pos': word_morpheme[2], 'pos1': word_morpheme[3]}\n",
    "        else:\n",
    "            return {'surface': word_morpheme[0], 'base': '', 'pos': '', 'pos1': ''}            \n",
    "        \n",
    "with open('input/neko.txt', encoding='utf-8') as f:\n",
    "    morphemes = [mapping_morpheme(lines.split('\\n')) for lines in f]\n",
    "\n",
    "print(morphemes[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31. 動詞\n",
    "動詞の表層形をすべて抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['のみ', '泣き', '飲ん', '飛ぶ', '走る', '臭え', '帰る', '帰る', '出来る', '見る', '来る', '見る', '出る', '見', '代え', '食い', 'つける', '忘れ', '考え', '食っ', '見る', '見る', '嗅い', '食お', '食う', '噛ん', '考え', '撫で', '倒れ', '分っ', '詰る', '黙っ', 'うる', '見る', '擲つ', '引か', '呼ぶ', '飛ん', '見る', '撓り', '考える', '欠け', '連れ', '困っ', '行く', '呼ん', '考える', 'やむをえ', '思い切っ', '飲も', '考え出す', 'かれ', '負け', '出来', '話し', '死ぬ', 'かよう', '余す', '知っ', '釣ら', '抜け', '知っ', '引き受け', '見る', '縮め', '聞い', 'し', '話せ', '見る', '行き', '追付こ', '構う', '後れ', '困ら', '驚く', '出れ', 'し', '恐れ入っ', '忘れ', '思わ', '知っ', '申す', 'い', '知ら', '蒸し', '話し', '引き', '思い出す', 'いら', '思う', '痛む', '入れ', '出来る', 'かよう', 'し', '見る', '振り向い', '笑い', '考えれ', '盗ら', '煮', '困っ', '舐め', 'あげ', '出来', 'し', 'とれん', 'され', '寝過ごし', '逃がす', '目ざす', 'ぼ', '瞬く', '起き上がる', '懸け', '見る', 'され', '分ら', '潰れ', 'まっ', 'ここ', '噛ん', '噛ん', '動か', '見る', 'なる', '見る', '買う', '知ら', 'しかる', '倦ん', '泣く', '死ね', 'せい', 'ひっくり返っ', '振り上げ', '振り上げ', '放し', 'みん', 'のみ', '逃げる', '飛ぶ', '落ちる', '落ちる', '落ちる', '進める', '睨め', '考え', 'のみ', 'しから', '聞い', 'やっ', '見', 'かよう', '生れ', '死ん', '聞く', '知る', 'かよう', 'し', '帰っ', '立っ', '入れ', '飛び込み', '見る', 'しから', '流し', '死な', 'のみ', '帰り', '鳴かせる', '打つ', '鳴く', '切れ', '殺せ', '打て', '困っ', '与っ', 'い', '吹き払い', 'ある', '吹き', '追い出さ', '這入れ', '放し', 'からかう', '聞い', 'され', 'からかい', 'からかう', 'からかう', '聞き', 'からかう', 'からかう', 'のみ', 'こしらえ', 'い', 'かよう', '申し合せ', '聞く', 'かよう', '分り', '禿げ', '砕け', 'し', '聞い', 'し', '中っ', '恐れ入ら', 'しから', '中っ', '詫び入る', 'しかる', '聞き', '聞き', 'よる', '笑う', '恐れ入っ', '来', '坐っ', '足る', '驚か', 'され', '出来る', '分け', 'なろ', '持っ', '見る', '吸い取ら', 'あれ', 'し', '読ん', '分ら', 'わから', '困っ', '死ん', '見る', '恐れ入り', '休ん', 'のみ', 'のみ', 'かる', 'なら', '思う', 'すん', 'すん', '覚め', 'のみ', '起きる', '見る', '起きる', '怒る', '起き直り', '見る', '聞く', '待ちかね', 'しから', '考える', 'とん', 'すん', '持て余す', '使いこなせ', '打ち', '飛びつき', 'とん', 'とん', '拾っ', '取払っ', 'すん', '取ら', '誓っ', '知ら', 'こん', 'かよう', '困っ', '待っ', 'いら', 'いら', 'す', 'し', 'のみ', '寄りつい', '聞く', '云わ', '試し', '聞か', '笑わ', 'しから', '打ちゃ', '救っ', '負け', 'しから', '引き寄せ', '入ら', '思い切っ', '死ぬ', '行く', '考える', 'ごまかす', '食う', '生じ', '見つかれ', 'だまっ', '振り向い', '買う', '聞く', '売る', '読める', '弾か', '弾け', '出れ', '起きる', '困っ', '断わる', '知ら', '寝', '借り', 'い', '死ぬ', '云う', 'あっ', '出来る', 'いっし', '合わ', '出', '利か', '見', 'いい', '聞い', '立っ', '坐っ', '出', '出来る', '出', 'つづい', '悟っ', '転がれ', '死ぬ', '死ん', '思い切っ', '飲む', '飲ん', '起っ', '出る', '寝', '減れ', '飛び', 'もがけ', 'もぐれ', 'あがり', '出', '死ん']\n"
     ]
    }
   ],
   "source": [
    "print([morpheme['surface'] for morpheme in morphemes if morpheme['pos1'].find('動詞') == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32. 動詞の原形\n",
    "動詞の原形をすべて抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ノミ', 'ナキ', 'ノン', 'トブ', 'ハシル', 'ニオエ', 'カエル', 'カエル', 'デキル', 'ミル', 'クル', 'ミル', 'デル', 'ミ', 'カエ', 'クイ', 'ツケル', 'ワスレ', 'カンガエ', 'クッ', 'ミル', 'ミル', 'カイ', 'クオ', 'クウ', 'カン', 'カンガエ', 'ナデ', 'タオレ', 'ワカッ', 'ツマル', 'ダマッ', 'ウル', 'ミル', 'ナゲウツ', 'ヒカ', 'ヨブ', 'トン', 'ミル', 'シワリ', 'カンガエル', 'カケ', 'ツレ', 'コマッ', 'イク', 'ヨン', 'カンガエル', 'ヤムヲエ', 'オモイキッ', 'ノモ', 'カンガエダス', 'カレ', 'マケ', 'デキ', 'ハナシ', 'シヌ', 'カヨウ', 'アマス', 'シッ', 'ツラ', 'ヌケ', 'シッ', 'ヒキウケ', 'ミル', 'チヂメ', 'キイ', 'シ', 'ハナセ', 'ミル', 'イキ', 'オイツコ', 'カマウ', 'オクレ', 'コマラ', 'オドロク', 'デレ', 'シ', 'オソレイッ', 'ワスレ', 'オモワ', 'シッ', 'モウス', 'イ', 'シラ', 'ムシ', 'ハナシ', 'ヒキ', 'オモイダス', 'イラ', 'オモウ', 'イタム', 'イレ', 'デキル', 'カヨウ', 'シ', 'ミル', 'フリムイ', 'ワライ', 'カンガエレ', 'トラ', 'ニ', 'コマッ', 'ナメ', 'アゲ', 'デキ', 'シ', 'トレン', 'サレ', 'ネスゴシ', 'ニガス', 'メザス', 'ボ', 'マバタク', 'オキアガル', 'カケ', 'ミル', 'サレ', 'ワカラ', 'ツブレ', 'マッ', 'ココ', 'カン', 'カン', 'ウゴカ', 'ミル', 'ナル', 'ミル', 'カウ', 'シラ', 'シカル', 'ウン', 'ナク', 'シネ', 'セイ', 'ヒックリカエッ', 'フリアゲ', 'フリアゲ', 'ハナシ', 'ミン', 'ノミ', 'ニゲル', 'トブ', 'オチル', 'オチル', 'オチル', 'ススメル', 'ネメ', 'カンガエ', 'ノミ', 'シカラ', 'キイ', 'ヤッ', 'ミ', 'カヨウ', 'ウマレ', 'シン', 'キク', 'シル', 'カヨウ', 'シ', 'カエッ', 'タッ', 'イレ', 'トビコミ', 'ミル', 'シカラ', 'ナガシ', 'シナ', 'ノミ', 'カエリ', 'ナカセル', 'ウツ', 'ナク', 'キレ', 'コロセ', 'ブテ', 'コマッ', 'アズカッ', 'イ', 'フキハライ', 'アル', 'フキ', 'オイダサ', 'ハイイレ', 'ハナシ', 'カラカウ', 'キイ', 'サレ', 'カラカイ', 'カラカウ', 'カラカウ', 'キキ', 'カラカウ', 'カラカウ', 'ノミ', 'コシラエ', 'イ', 'カヨウ', 'モウシアワセ', 'キク', 'カヨウ', 'ワカリ', 'ハゲ', 'クダケ', 'シ', 'キイ', 'シ', 'アタッ', 'オソレイラ', 'シカラ', 'アタッ', 'ワビイル', 'シカル', 'キキ', 'キキ', 'ヨル', 'ワラウ', 'オソレイッ', 'コ', 'スワッ', 'タル', 'オドロカ', 'サレ', 'デキル', 'ワケ', 'ナロ', 'モッ', 'ミル', 'スイトラ', 'アレ', 'シ', 'ヨン', 'ワカラ', 'ワカラ', 'コマッ', 'シン', 'ミル', 'オソレイリ', 'ヤスン', 'ノミ', 'ノミ', 'カル', 'ナラ', 'オモウ', 'スン', 'スン', 'サメ', 'ノミ', 'オキル', 'ミル', 'オキル', 'オコル', 'オキナオリ', 'ミル', 'キク', 'マチカネ', 'シカラ', 'カンガエル', 'トン', 'スン', 'モテアマス', 'ツカイコナセ', 'ウチ', 'トビツキ', 'トン', 'トン', 'ヒロッ', 'トリハラッ', 'スン', 'トラ', 'チカッ', 'シラ', 'コン', 'カヨウ', 'コマッ', 'マッ', 'イラ', 'イラ', 'ス', 'シ', 'ノミ', 'ヨリツイ', 'キク', 'イワ', 'タメシ', 'キカ', 'ワラワ', 'シカラ', 'ウチャ', 'スクッ', 'マケ', 'シカラ', 'ヒキヨセ', 'ハイラ', 'オモイキッ', 'シヌ', 'イク', 'カンガエル', 'ゴマカス', 'クウ', 'ショウジ', 'ミツカレ', 'ダマッ', 'フリムイ', 'カウ', 'キク', 'ウル', 'ヨメル', 'ヒカ', 'ヒケ', 'デレ', 'オキル', 'コマッ', 'コトワル', 'シラ', 'ネ', 'カリ', 'イ', 'シヌ', 'イウ', 'アッ', 'デキル', 'イッシ', 'アワ', 'デ', 'キカ', 'ミ', 'イイ', 'キイ', 'タッ', 'スワッ', 'デ', 'デキル', 'デ', 'ツヅイ', 'サトッ', 'コロガレ', 'シヌ', 'シン', 'オモイキッ', 'ノム', 'ノン', 'オコッ', 'デル', 'ネ', 'ヘレ', 'トビ', 'モガケ', 'モグレ', 'アガリ', 'デ', 'シン']\n"
     ]
    }
   ],
   "source": [
    "print([morpheme['base'] for morpheme in morphemes if morpheme['pos1'].find('動詞') == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33. サ変名詞\n",
    "サ変接続の名詞をすべて抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['欠伸', '同盟', '邂逅', '御馳走', '要心', '料理', '達観', '勘定', '白状', '煩悶', '説明', '参考', '敬服', '登場', '入浴', '感服', '——', '競争', '返事', '粘着', '卒業', '油断', '——', '——', '——', '——', '——', '——', '——', '——', '——', '——', '——', '探険', '探険', '——', '点滴', '——', '——', '——', '——', '——', '——', '——', '——', '談話', '——', '——', '——', '伝染', '返答', '——', '——', '——', '——', '——', '——', '——', '——', '長生', '是非', '——', '学問', '——', '活動', '苦労', '話', '休養', '回顧', '——', '——', '——', '換言', '製作', '——', '——', '——', '告訴', 'そげん', '——', '——', '——', '——', '——', '——', '休養', '——', '戦闘', '心配', '安心', '休養', '等分', '——', '昼寝', '——', '鍛冶', '午睡', '比較', '結婚', '——', '山盛り', '——', '——', '——', '——', '朗読', '着付け', '——', '説明', '註釈', '運動', '病気', '洋行', '進化', '運動', '運動', '——', '——', '真似', '——', '左右', '退却', '運動', '——', '——', '開校', '失礼', '学問', '用心', '——', '——', '——', '——', '——', '病気', '免職', '換言', '比較', '交際', '蚕食', '教育', '教育', '——', '辞職', '——', '逆上', '逆上', '逆上', '煩悶', '深入り', '借金', '連想', '降参', '苦心', '運動', '逆上', '逆上', '——', '是非', '——', '心配', '診察', '交際', '喧嘩', '下宿', '代議', '——', '換言', '教育', '——', '——', '——', '教育', '寄附', '寄附', '——', '是非', '挨拶', '遠慮', '——', '——', '——', '——', '——', '探偵', '返事', '掃除', '試験', '探偵', '遠慮', 'あくび', '掃除', '生長', '承知', '決心', '——', '——', '——', '——', '——', '——', '——', '交際', '退校', '関係', '珍重', '侮辱', '監督', '学問', '——', '成敗', '——', '座禅', '——', '——', '——', '——', '——', '独習', '参考', '——', '——', '——', '——', '勘定', '——', '——', '——', '慰藉', '——', '往来', '下宿', '——', '油断', '——', '——', '——', '油断', '——', '探偵', '探偵', '探偵', '喧嘩', '探偵', '御馳走', '議論', '自殺', '謝罪', '主張', '発達', '心配', '開化', '参考', '披露', '——', '是非', '是非', '——', '——', '——', '油断', '行水']\n"
     ]
    }
   ],
   "source": [
    "print([morpheme['surface'] for morpheme in morphemes if morpheme['pos1'] == '名詞-サ変接続'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34. 「AのB」\n",
    "2つの名詞が「の」で連結されている名詞句を抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['彼の掌', '主人の彩色', '元の通り', '門の格子', '主人のよう', '在来の通り', 'つもりのところ', '感謝の意', 'トチメンボーの復讐', '門の内', '教師の所', '冊の内', '埒の方', '車屋の神', '活眼の士', 'さんの話', '護の恐れ', '雪隠の横', '右手の指', '心の故', '迷亭の食い気', '派の元祖', '鼠の糞', '神の製作', '山の芋の寄贈', 'これらの凡眼', '軽蔑の極', '屋のせがれ', '硝子の球', '奥さんのよう', '本の枝', '魚の往生', '叉の上', '左の方', '桶の方', '敷居の上', '家主の伝兵衛', '目の間', '作家の頭', '目垣の外側', '館の生徒', '癪の源', '養子の代', '自己の研究', '風変りの光彩', '敵の太刀', '六の背', '一般の淑女', '回の声', '打算の限り', '町内のもの', '頭のつんつるてん', 'ナポレオンのそれ', '僕の方', '退校の処分', '右の手', '狂乱の態度', '宮廷の礼', '自分の恥', '例の一大', '君の世の中']\n"
     ]
    }
   ],
   "source": [
    "def tabbed_str_to_dict(tabbed_str: str) -> dict:\n",
    "    \"\"\"\n",
    "    例えば「次第に   シダイニ    次第に   副詞-一般   」のようなタブ区切りで形態素を表す文字列をDict型に変換する.\n",
    "    :param tabbed_str タブ区切りで形態素を表す文字列\n",
    "    :return Dict型で表された形態素\n",
    "    \"\"\"\n",
    "    elements = tabbed_str.split()\n",
    "    if 0 < len(elements) < 4:\n",
    "        return {'surface': elements[0], 'base': '', 'pos': '', 'pos1': ''}\n",
    "    else:\n",
    "        return {'surface': elements[0], 'base': elements[1], 'pos': elements[2], 'pos1': elements[3]}\n",
    "    \n",
    "with open('output/neko.txt.mecab', encoding='utf-8') as file_wrapper:\n",
    "    morphemes = [tabbed_str_to_dict(line) for line in file_wrapper]\n",
    "    \n",
    "import ngram\n",
    "def trigram_list(lst: list, n: int = 3) -> list:\n",
    "    \"\"\"\n",
    "    listをNグラム化する.\n",
    "    :param lst Nグラム化対象のリスト\n",
    "    :param n N (デフォルトは N = 3)\n",
    "    :return Nグラム化済みのリスト\n",
    "    \"\"\"\n",
    "    index = ngram.NGram(N=n)\n",
    "    return [term for term in index.ngrams(lst)]\n",
    "\n",
    "\n",
    "def is_noun_no_noun(words: list) -> bool:\n",
    "    \"\"\"\n",
    "    3つの単語から成るリストが「名詞-の-名詞」という構成になっているかを判定する.\n",
    "    :param words 3つの単語から成るリスト\n",
    "    :return bool (True:「名詞-の-名詞」という構成になっている / False:「名詞-の-名詞」という構成になっていない)\n",
    "    \"\"\"\n",
    "    return (type(words) == list) and (len(words) == 3) and \\\n",
    "           (words[0]['pos1'].find('名詞') == 0) and \\\n",
    "           (words[1]['surface'] == 'の') and \\\n",
    "           (words[2]['pos1'].find('名詞') == 0)\n",
    "\n",
    "\n",
    "# 「名詞-の-名詞」を含むNグラムのみを抽出\n",
    "noun_no_noun = [ngrams for ngrams in trigram_list(morphemes) if is_noun_no_noun(ngrams)]\n",
    "\n",
    "# 表層を取り出して結合する\n",
    "noun_no_noun = [''.join([word['surface'] for word in ngram]) for ngram in noun_no_noun]\n",
    "\n",
    "# 結果の確認\n",
    "print(noun_no_noun[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35. 名詞の連接\n",
    "名詞の連接（連続して出現する名詞）を最長一致で抽出せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['毎日毎日', '……', '……', '……']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def is_same_noun(words: list) -> bool:\n",
    "    return (type(words) == list) and (len(words) == 2) and \\\n",
    "           (words[0] == words[1])\n",
    "\n",
    "# 「名詞-の-名詞」を含むNグラムのみを抽出\n",
    "noun_no_noun = [ngrams for ngrams in bigram_list(morphemes) if is_same_noun(ngrams)]\n",
    "\n",
    "# 表層を取り出して結合する\n",
    "noun_no_noun = [''.join([word['surface'] for word in ngram]) for ngram in noun_no_noun]\n",
    "\n",
    "# 結果の確認\n",
    "print(noun_no_noun[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['何吾輩', '近松それ藪', '吾輩吾輩', 'これ山の芋', '海水浴魚一猫', '今度形勢教育気の毒校長', '影多く', '伊藤主人あくび', '主人独り']\n"
     ]
    }
   ],
   "source": [
    "def morphemes_to_noun_array(morphemes: list) -> list:\n",
    "    nouns_list = []\n",
    "    nouns = []\n",
    "\n",
    "    for morpheme in morphemes:\n",
    "        if morpheme['pos1'].find('名詞') >= 0:\n",
    "            nouns.append(morpheme)\n",
    "        elif (morpheme['pos1'] == '記号-句点') | (morpheme['pos1'].find('名詞') < 0):\n",
    "            nouns_list.append(nouns)\n",
    "            nouns = []\n",
    "\n",
    "    return [nouns for nouns in nouns_list if len(nouns) > 1]\n",
    "\n",
    "\n",
    "noun_array = [''.join([noun['surface'] for noun in nouns]) for nouns in morphemes_to_noun_array(morphemes)]\n",
    "\n",
    "# 結果の確認\n",
    "print(noun_array[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36. 単語の出現頻度\n",
    "文章中に出現する単語とその出現頻度を求め，出現頻度の高い順に並べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('「', 2345), ('EOS', 754), ('\\u3000', 396), ('主人', 189), ('吾輩', 155), ('しかし', 136), ('この', 131), ('これ', 128), ('その', 124), ('それ', 113), ('——', 110), ('」', 82), ('ただ', 71), ('何', 65), ('僕', 58), ('人間', 56), ('今', 54), ('迷亭', 54), ('すると', 49), ('彼', 49)]\n"
     ]
    }
   ],
   "source": [
    "def get_frequency(words: list) -> dict:\n",
    "    \"\"\"\n",
    "    単語のリストを受け取って、単語をキーとして、頻度をバリューとする辞書を返す.\n",
    "    :param words 単語のリスト\n",
    "    :return dict 単語をキーとして、頻度をバリューとする辞書\n",
    "    \"\"\"\n",
    "    frequency = {}\n",
    "    for word in words:\n",
    "        if frequency.get(word):\n",
    "            frequency[word] += 1\n",
    "        else:\n",
    "            frequency[word] = 1\n",
    "\n",
    "    return frequency\n",
    "\n",
    "\n",
    "frequency = get_frequency([morpheme['surface'] for morpheme in morphemes])\n",
    "\n",
    "# ソート\n",
    "frequency = [(k, v) for k, v in sorted(frequency.items(), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "# 結果の確認\n",
    "print(frequency[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37. 頻度上位10語\n",
    "出現頻度が高い10語とその出現頻度をグラフ（例えば棒グラフなど）で表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Top 10 frequent words')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# 37. 出現頻度が高い10語とその出現頻度をグラフ（例えば棒グラフなど）で表示せよ．\n",
    "words = [f[0] for f in frequency[0:10]]\n",
    "x_pos = np.arange(len(words))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.bar(x_pos, [f[1] for f in frequency[0:10]], align='center', alpha=0.4)\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(words)\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Top 10 frequent words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38. ヒストグラム\n",
    "単語の出現頻度のヒストグラム（横軸に出現頻度，縦軸に出現頻度をとる単語の種類数を棒グラフで表したもの）を描け．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tai-hatake/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(dict(frequency).values())\n",
    "freq.sort(reverse=True)\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.hist(freq, bins=50, range=(0, 50))\n",
    "ax2.set_title('Histogram of word count')\n",
    "ax2.set_xlabel('Word count')\n",
    "ax2.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 39. Zipfの法則\n",
    "単語の出現頻度順位を横軸，その出現頻度を縦軸として，両対数グラフをプロットせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tai-hatake/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "rank = list(range(1, len(freq) + 1))\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.plot(freq, rank)\n",
    "ax3.set_xlabel('Rank')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Zipf low')\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
